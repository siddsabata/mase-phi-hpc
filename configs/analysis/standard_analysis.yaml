# TracerX Marker Selection Pipeline - Standard Analysis Configuration
# Complete configuration for steps 1-4: Bootstrap → PhyloWGS → Aggregation → Marker Selection

# Patient and analysis identification
patient_id: "ppi_115"

# Input files and directories - UPDATE THESE PATHS FOR YOUR ENVIRONMENT
input:
  ssm_file: "/home/ssabata/mase-phi-hpc/data/vaf_filter_test/ssm_ppi_115.txt"
  code_dir: "/home/ssabata/mase-phi-hpc/"  # Base directory of the TracerX-MP repository

# Output configuration
output:
  base_dir: "/home/ssabata/patient_data/filter_test/"  # Patient base directory

# Step 1: Bootstrap configuration
bootstrap:
  num_bootstraps: 10  # Number of bootstrap samples to generate

# Step 2: PhyloWGS configuration  
phylowgs:
  num_chains: 5      # Number of chains used for PhyloWGS 
  parallel_limit: 50  # Maximum number of parallel jobs in SLURM array; make sure this one is being used 

# Step 3: Aggregation configuration
aggregation:
  method: "phylowgs" # not used?
  generate_visualizations: true # not used 
  sample_prefix: "Region"  # Prefix for sample names in visualizations
  custom_sample_names: []  # remove 

# Step 4: Marker selection configuration
marker_selection:
  read_depth: 1500
  # Note: VAF filtering (threshold=0.9, any_high strategy) now applied in bootstrap stage
  
  # Optimization parameters
  optimization:
    lambda1_values: [1.0, 0.0]  # Fraction vs structure weighting
    lambda2_values: [0.0, 1.0]  # Corresponds to lambda1_values
    max_iterations: null        # null = all possible markers, or specify max number

# HPC/SLURM configuration
hpc:
  # Step-specific resource allocation
  bootstrap:
    partition: "pool1"
    cpus_per_task: 2
    memory: "16G"
    walltime: "02:00:00"
    conda_env: "preprocess_env" # not used 
  
  phylowgs:
    partition: "pool1" 
    cpus_per_task: 5
    memory: "8G"
    walltime: "12:00:00"
    conda_env: "phylowgs_env" # not used 
    array_throttle: 50  # %10 in SLURM array syntax
  
  aggregation:
    partition: "pool1"
    cpus_per_task: 1  
    memory: "16G"
    walltime: "04:00:00"
    conda_env: "aggregation_env" # not used
  
  marker_selection:
    partition: "pool1"
    cpus_per_task: 1
    memory: "16G" 
    walltime: "06:00:00"
    conda_env: "markers_env" # not used 
    modules: ["gurobi1102"]  # Required modules to load

    # Validation and debugging: remove 
validation:
  validate_inputs: true
  check_dependencies: true
  debug_mode: false

  # Pipeline orchestration: remove 
orchestration:
  run_sequential: false    # If true, run steps sequentially instead of using dependencies
  cleanup_temp_files: true
  save_intermediate: true
  email_notifications: false  # Set to email address for job completion notifications
